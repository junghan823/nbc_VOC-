# LMS 공지 문의 VOC 자동 분석 시스템 PRD

## 1. 프로젝트 개요
- **프로젝트 명**: LMS 공지 문의 자동 분석 시스템
- **목적**: LMS 공지 문의 데이터를 주기적으로 자동 분석하여 학습관리 스쿼드가 VOC 트렌드를 실시간에 가깝게 파악하고 대응 시간을 단축한다.
- **배경**: 공지 문의 채널에 누적된 1,500건 이상의 VOC가 수동 대응에만 활용되고 있어 반복 패턴 파악, 긴급 이슈 식별, 개선 인사이트 도출이 어려운 상태다.

## 2. 목표 및 성공 지표
- **핵심 목표**: VOC 데이터 자동 분석과 실시간 대시보드 제공으로 학습관리 스쿼드가 즉시 활용 가능한 인사이트를 확보한다.
- **분석 목표**: 카테고리별 집계, 전월 대비 증감률 계산, 긴급도/불만도/온도 지표 산출, 반복 패턴 감지 및 FAQ 제안.
- **전달 목표**: Streamlit 기반 대시보드에서 최신 분석 결과를 공유하고, 필요 시 자동화된 JSON 리포트로 팀 협업을 지원한다.
- **운영 가드레일**:
  - 긴급/온도 판정 재현율 90% 이상을 1차 완료 기준으로 삼고, 샘플 검증을 통해 보정한다.
  - 대시보드 주간 활성 사용자와 조회수(1회 이상 방문 기준)를 추적해 활용도를 파악한다.

## 3. 데이터 소스
- **위치**: Google Sheet `raw data` 탭 (https://docs.google.com/spreadsheets/d/19z32Cbsfaf8zdDX_eXQAEPlBuNrCxK4AnyQX07dib0M/edit?gid=0#gid=0)
- **주요 컬럼**: `문의일자`(K열, UTC), `문의내용`(Q열), `대분류`(R열), `소분류`(S열)
- **데이터량**: 약 1,500건 (2024-06-30 이후)
- **업데이트 정책**: 신규 문의가 추가되고 일부 내용이 수정될 수 있으나, MVP 단계에서는 최초 수집 시점 텍스트를 기준으로 분석한다.

## 4. 분석 구조
- **수집 및 파이프라인**: Python 스크립트(`voc_analyzer.py`)가 Google Sheets API로 데이터 수집 후 pandas DataFrame으로 가공한다.
- **분석 엔진**: OpenAI GPT (gpt-4o 또는 비용에 따라 gpt-4o-mini, gpt-3.5-turbo 등 선택)
- **배치 처리**: 건당 분석 시 최대 20건씩 청크 처리하여 API 호출 부담을 최소화한다.
- **분석 항목**:
  - `urgency`(1~5), `complaint_level`(1~5), `temperature`(cold/warm/hot), `reason`
  - 카테고리별 패턴 요약과 FAQ 후보(question/answer, frequency)
  - 최근 30일/90일 총량 및 Top5 카테고리, 전월 대비 증감률
- **긴급 VOC 판정 로직**:
  - 긴급 키워드 포함(예: 출석, 퇴실, 발급, 장애, 피해 등), 감정 또는 불만 점수 4 이상, 피해 확대 표현 1개 이상 조건을 조합한다.
  - 위 조건 2개 이상 충족 시 온도 `hot`, 1개 충족 시 `warm`, 모두 미충족 시 `cold`로 분류한다.
- **중복 방지**: 문의일자+문의내용 해시 기준으로 처리 로그를 남기고, 동일 해시는 재분석하지 않는다(수정 건은 재분석 미지원).
- **결과 저장소**: 로컬 `voc_report.json`에 정규화된 JSON 구조로 저장하며, 필요 시 S3/Drive로 업로드 옵션을 남겨둔다.

## 5. 리포트 구성 및 발송
- **주기**: 기본적으로 하루 1회 자동 실행, 필요 시 수동 실행 지원. (주기 조정은 스케줄러 설정으로 변경)
- **배포 방식**: Streamlit 대시보드(`voc_dashboard.py`)가 `voc_report.json`을 읽어 실시간 시각화 제공.
- **대시보드 구성 요소**:
  - 최근 30일/90일 통계 및 총량 카드
  - Top5 카테고리 막대 그래프
  - 전월 대비 증감률 히트맵/막대 그래프
  - 긴급/온도 높은 VOC 리스트 (필터링 가능)
  - FAQ 제안 카드(패턴/추천 질문·답변)
- **추가 공유**: 필요 시 JSON 파일을 메일 또는 Slack으로 전송하도록 확장.

## 6. 시스템 구성
```
Google Sheets (raw data)
        │
        ▼
Python 스크립트 (데이터 수집 및 전처리)
        │
        ▼
OpenAI GPT 분석 (긴급도/패턴/FAQ)
        │
        ▼
JSON 리포트 저장 (voc_report.json)
        │
        ▼
Streamlit 대시보드 (시각화 및 공유)
```

## 7. 운영 및 장애 대응
- **API 키 관리**: `.env`에 OpenAI 키, OAuth `credentials.json`은 버전관리 제외.`.gitignore`로 보호.
- **호출 상한**: 실행당 최대 500건 분석, 호출량 초과 시 토큰 비용 모니터링.
- **재시도 정책**: API 오류 시 최대 3회 재시도(지수 백오프: 30s, 60s, 120s). 실패 시 에러 로그와 상태 코드 기록.
- **스케줄링 옵션**:
  - 로컬 크론 혹은 Windows Task Scheduler로 `python voc_analyzer.py` 실행.
  - GitHub Actions/Cloud Scheduler로 일일 실행 자동화(비용·보안 고려 후 결정).
- **장애 알림**:
  - 실행 실패 시 이메일/Slack Webhook 알림(추가 예정), 최소한 로그 파일과 표준 출력에 에러 스택 기록.
- **보안/컴플라이언스**: Google Sheets 공유 권한 최소화, Streamlit 대시보드는 인증된 사용자만 접근(비공개 링크 또는 SSO). 민감 데이터 마스킹 지침 수립.

## 8. 향후 확장
- 다중 VOC 채널(ChannelTalk, Slack, Google Form 등) 통합 시 공통 스키마 설계 및 소스별 전처리 모듈 추가.
- Streamlit 외 별도 웹 서비스/Notion 임베드 연동.
- OpenAI 이외 모델 지원(Claude, Vertex 등) 및 비용 최적화를 위한 캐싱.
- 긴급 VOC 실시간 알림(슬랙/이메일) 기능 추가.

## 9. 일정 및 다음 단계
- **MVP 범위**:
  1. Google Sheets OAuth 설정 및 `voc_analyzer.py` 기본 데이터 수집 구현
  2. pandas 기반 기본 통계(30/90일, Top5, 증감률) 계산
  3. OpenAI API 연동으로 긴급도/불만도/온도/FAQ 분석 결과 생성
  4. `voc_report.json` 저장 구조 확정 및 Streamlit 대시보드(`voc_dashboard.py`) 구현
  5. 로컬 스케줄러 또는 GitHub Actions로 자동 실행 시나리오 초안 구성
- **검증 플로우**:
  - 샘플 50건으로 긴급/온도 판정 품질 검증 및 FAQ 타당성 평가
  - 내부 사용자 대상 대시보드 피드백 수집 후 UX 개선
  - 자동 실행 1주 시범 운영으로 실패 알림 및 비용 모니터링 점검
