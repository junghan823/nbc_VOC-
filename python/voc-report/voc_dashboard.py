"""Streamlit dashboard for the VOC learning environment report."""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, List

import pandas as pd
import streamlit as st

DEFAULT_REPORT_PATH = Path(__file__).resolve().parent / "voc_report.json"


def load_report(path: Path = DEFAULT_REPORT_PATH) -> Dict[str, Any]:
    if not path.exists():
        st.warning(
            f"Report file not found at {path}. "
            "Run `python voc_analyzer.py --export-report` first."
        )
        return {}
    try:
        return json.loads(path.read_text())
    except json.JSONDecodeError as exc:
        st.error(f"Failed to parse report JSON: {exc}")
        return {}


def render_meta(meta: Dict[str, Any]) -> None:
    st.subheader("ğŸ“Š í•™ìŠµ í™˜ê²½ VOC ë¦¬í¬íŠ¸")
    if not meta:
        st.info("ë¦¬í¬íŠ¸ ë©”íƒ€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    cols = st.columns(3)
    cols[0].metric("ìƒì„±ì¼", meta.get("generated_at", "N/A")[:10])
    period = meta.get("analysis_period", {})
    start = period.get("start")
    end = period.get("end")
    cols[1].metric("ë¶„ì„ ê¸°ê°„", period.get("label", "N/A"))
    cols[2].metric("VOC ì´ëŸ‰", f"{meta.get('total_count', 0):,}")

    st.caption(
        f"ì§‘ê³„ ë²”ìœ„: {period.get('label', 'ìµœê·¼ 30ì¼')} "
        f"(ì‹œì‘: {start}, ì¢…ë£Œ: {end})"
    )


def render_top_issues(issues: List[Dict[str, Any]]) -> None:
    st.subheader("âš ï¸ ì´ë²ˆ ë‹¬ í•µì‹¬ ì´ìŠˆ Top5")
    if not issues:
        st.info("Top5 ì´ìŠˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    cols = st.columns(5)
    for col, issue in zip(cols, issues):
        change_pct = issue.get("change_pct", 0)
        emoji = (
            "ğŸ”´" if change_pct >= 30 else "ğŸŸ¡" if change_pct >= 10 else "ğŸŸ¢"
        )
        with col:
            st.markdown(
                f"**#{issue.get('rank', '?')} {issue.get('issue_key', 'ê¸°íƒ€')}**"
            )
            st.metric("30ì¼ ê±´ìˆ˜", issue.get("count", 0))
            st.metric(
                "ì „ì›” ëŒ€ë¹„",
                f"{change_pct:+.1f}%",
                help=f"ì§ì „ 30ì¼: {issue.get('previous_count', 0)}ê±´",
            )
            st.markdown(f"{emoji} ë³€í™” ìƒíƒœ")
            summary = issue.get("summary")
            if summary:
                st.caption(summary)
            quotes = issue.get("quotes", [])
            for quote in quotes:
                st.markdown(f"- {quote}")


def render_phase_analysis(
    phase_counts: Dict[str, Any],
    phase_breakdown: Dict[str, Any],
) -> None:
    st.subheader("ğŸ“š í•™ìŠµ ë‹¨ê³„ë³„ ì£¼ìš” ë¶ˆí¸")
    if not phase_breakdown:
        st.info("ë‹¨ê³„ë³„ ìƒì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    if phase_counts:
        summary_df = pd.DataFrame(
            [
                {"ë‹¨ê³„": phase, "ê±´ìˆ˜(30ì¼)": count}
                for phase, count in phase_counts.items()
            ]
        ).sort_values("ê±´ìˆ˜(30ì¼)", ascending=False)
        st.dataframe(summary_df, hide_index=True, use_container_width=True)

    phase_order = ["í•™ìŠµ ì¤€ë¹„", "í•™ìŠµ ì§„í–‰", "í•™ìŠµ ì§€ì›", "í–‰ì • ì²˜ë¦¬"]
    for phase in phase_order:
        detail = phase_breakdown.get(phase)
        if not detail:
            continue
        total = detail.get("total", 0)
        expander = st.expander(f"[{phase}] {total}ê±´ (ìµœê·¼ 30ì¼)")
        with expander:
            issues = detail.get("issues", [])
            if not issues:
                st.write("ì„¸ë¶€ ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                data = []
                for issue in issues:
                    data.append(
                        {
                            "ì´ìŠˆ": issue.get("issue_key"),
                            "ê±´ìˆ˜(30ì¼)": issue.get("count"),
                            "ì „ì›” 30ì¼": issue.get("previous_count"),
                            "ì¦ê°ë¥ ": f"{issue.get('change_pct', 0):+.1f}%",
                            "ìš”ì•½": issue.get("summary"),
                        }
                    )
                st.dataframe(pd.DataFrame(data), hide_index=True, use_container_width=True)
                for issue in issues:
                    quotes = issue.get("quotes", [])
                    if quotes:
                        st.markdown(f"- **{issue.get('issue_key')}**")
                        for quote in quotes:
                            st.markdown(f"  - {quote}")


def render_quotes(quotes: List[str]) -> None:
    st.subheader("ğŸ’¬ ëŒ€í‘œ ìˆ˜ê°•ìƒ ë°œí™”")
    if not quotes:
        st.info("ëŒ€í‘œ ë°œí™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for quote in quotes:
        st.markdown(
            f"> â€œ{quote}â€",
        )


def render_recommendations(recommendations: Dict[str, Any]) -> None:
    st.subheader("ğŸ›  ê¶Œì¥ ì¡°ì¹˜")
    if not recommendations:
        st.info("ê¶Œì¥ ì¡°ì¹˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    tabs = st.tabs(["ë‹¨ê¸°", "ì¤‘ê¸°", "ëª¨ë‹ˆí„°ë§"])
    keys = ["short_term", "mid_term", "long_term"]
    for tab, key in zip(tabs, keys):
        with tab:
            actions = recommendations.get(key, [])
            if not actions:
                st.write("ì¶”ê°€ ì˜ˆì •")
            else:
                for action in actions:
                    st.markdown(f"- {action}")


def main() -> None:
    st.set_page_config(page_title="VOC ë¦¬í¬íŠ¸", layout="wide")
    report = load_report()
    if not report:
        return

    render_meta(report.get("meta", {}))
    st.divider()
    render_top_issues(report.get("issues", {}).get("top_recent_30d", []))
    st.divider()
    issues_section = report.get("issues", {})
    render_phase_analysis(
        issues_section.get("phase_counts", {}),
        issues_section.get("phase_breakdown", {}),
    )
    st.divider()
    render_quotes(report.get("samples", {}).get("recent_quotes", []))
    st.divider()
    render_recommendations(report.get("recommendations", {}))


if __name__ == "__main__":
    main()
